{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publicationName</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>subjectArea</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Effects of iron content on the microstructure ...</td>\n",
       "      <td>Materials Chemistry and Physics</td>\n",
       "      <td>microstructure corrosion behavior hot rolled t...</td>\n",
       "      <td>EIS Microstructure Pitting corrosion Polarizat...</td>\n",
       "      <td>MATE</td>\n",
       "      <td>01/10/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The critical factors of research and innovatio...</td>\n",
       "      <td>International Journal of Trade and Global Markets</td>\n",
       "      <td>copyright   inderscience enterprises ltd. univ...</td>\n",
       "      <td>Critical factors Innovation creation Public un...</td>\n",
       "      <td>BUSI</td>\n",
       "      <td>01/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the occiput-wall distance valid and reliabl...</td>\n",
       "      <td>Musculoskeletal Science and Practice</td>\n",
       "      <td>background hyperkyphosis frequently found nowa...</td>\n",
       "      <td>Cobb angle Dowager's hump Round back Spine</td>\n",
       "      <td>HEAL</td>\n",
       "      <td>01/12/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comparison of soil composition between farmlan...</td>\n",
       "      <td>Eurasian Journal of Analytical Chemistry</td>\n",
       "      <td>society innovative research rights reserved ...</td>\n",
       "      <td>Agriculture land management Conserved area Soi...</td>\n",
       "      <td>CHEM</td>\n",
       "      <td>01/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The influence of neighbor effect and urbanizat...</td>\n",
       "      <td>Progress in Transplantation</td>\n",
       "      <td>natco rights reserved introduction population ...</td>\n",
       "      <td>Choice Consumer wellness Decision-making Neigh...</td>\n",
       "      <td>MEDI</td>\n",
       "      <td>01/03/2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Effects of iron content on the microstructure ...   \n",
       "1  The critical factors of research and innovatio...   \n",
       "2  Is the occiput-wall distance valid and reliabl...   \n",
       "3  Comparison of soil composition between farmlan...   \n",
       "4  The influence of neighbor effect and urbanizat...   \n",
       "\n",
       "                                     publicationName  \\\n",
       "0                    Materials Chemistry and Physics   \n",
       "1  International Journal of Trade and Global Markets   \n",
       "2               Musculoskeletal Science and Practice   \n",
       "3           Eurasian Journal of Analytical Chemistry   \n",
       "4                        Progress in Transplantation   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  microstructure corrosion behavior hot rolled t...   \n",
       "1  copyright   inderscience enterprises ltd. univ...   \n",
       "2  background hyperkyphosis frequently found nowa...   \n",
       "3    society innovative research rights reserved ...   \n",
       "4  natco rights reserved introduction population ...   \n",
       "\n",
       "                                            keywords subjectArea  \\\n",
       "0  EIS Microstructure Pitting corrosion Polarizat...        MATE   \n",
       "1  Critical factors Innovation creation Public un...        BUSI   \n",
       "2         Cobb angle Dowager's hump Round back Spine        HEAL   \n",
       "3  Agriculture land management Conserved area Soi...        CHEM   \n",
       "4  Choice Consumer wellness Decision-making Neigh...        MEDI   \n",
       "\n",
       "  publication_date  \n",
       "0       01/10/2018  \n",
       "1       01/01/2018  \n",
       "2       01/12/2018  \n",
       "3       01/01/2018  \n",
       "4       01/03/2018  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.set_index('Unnamed: 0', inplace=True)\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# df.index.name = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16319, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "publicationName     0\n",
       "abstract            0\n",
       "keywords            0\n",
       "subjectArea         0\n",
       "publication_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import compute_class_weight\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns: title, publicationName, abstract, keywords, subjectArea\n",
    "\n",
    "# Text preprocessing and vectorization\n",
    "text_data = df['title'] + ' ' + df['publicationName'] # + ' ' + df['keywords']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "y = df['subjectArea']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_encoded\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: np.float64(0.5525925925925926),\n",
       " 1: np.float64(2.878086419753086),\n",
       " 2: np.float64(0.5354579385587137),\n",
       " 3: np.float64(1.6847335140018067),\n",
       " 4: np.float64(0.9054653904841171),\n",
       " 5: np.float64(0.6337071015970098),\n",
       " 6: np.float64(0.5839595634281625),\n",
       " 7: np.float64(30.21990740740741),\n",
       " 8: np.float64(2.313485734538366),\n",
       " 9: np.float64(2.429741299088033),\n",
       " 10: np.float64(4.435949711179069),\n",
       " 11: np.float64(1.176444083986663),\n",
       " 12: np.float64(0.7079334092511252),\n",
       " 13: np.float64(0.8759393451422437),\n",
       " 14: np.float64(4.278924942641757),\n",
       " 15: np.float64(1.2210063598952487),\n",
       " 16: np.float64(0.7519728126260008),\n",
       " 17: np.float64(2.4669312169312168),\n",
       " 18: np.float64(0.17537849783043835),\n",
       " 19: np.float64(1.9735449735449735),\n",
       " 20: np.float64(2.3701888162672478),\n",
       " 21: np.float64(4.518864659051575),\n",
       " 22: np.float64(1.3139090177133654),\n",
       " 23: np.float64(0.98476276684016),\n",
       " 24: np.float64(4.31712962962963),\n",
       " 25: np.float64(0.7965708707059613),\n",
       " 26: np.float64(1.7330412850126111)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [00:02:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       198\n",
      "           1       0.91      0.78      0.84        40\n",
      "           2       0.72      0.60      0.65       207\n",
      "           3       0.70      0.58      0.63        64\n",
      "           4       0.88      0.80      0.84       159\n",
      "           5       0.79      0.79      0.79       200\n",
      "           6       0.79      0.85      0.82       210\n",
      "           7       1.00      0.22      0.36         9\n",
      "           8       0.82      0.69      0.75        48\n",
      "           9       0.79      0.61      0.69        38\n",
      "          10       0.62      0.36      0.45        28\n",
      "          11       0.78      0.81      0.80        96\n",
      "          12       0.79      0.72      0.75       208\n",
      "          13       0.77      0.79      0.78       131\n",
      "          14       0.80      0.29      0.42        28\n",
      "          15       0.86      0.73      0.79       113\n",
      "          16       0.81      0.84      0.82       170\n",
      "          17       0.87      0.69      0.77        58\n",
      "          18       0.67      0.92      0.78       646\n",
      "          19       0.97      0.90      0.93        71\n",
      "          20       0.82      0.65      0.73        49\n",
      "          21       0.86      0.72      0.78        25\n",
      "          22       0.91      0.80      0.85        96\n",
      "          23       0.94      0.84      0.89       127\n",
      "          24       0.85      0.58      0.69        38\n",
      "          25       0.69      0.56      0.62       132\n",
      "          26       0.95      0.93      0.94        75\n",
      "\n",
      "    accuracy                           0.78      3264\n",
      "   macro avg       0.82      0.70      0.74      3264\n",
      "weighted avg       0.79      0.78      0.77      3264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train XGBoost model\n",
    "model = XGBClassifier(scale_pos_weight=class_weight_dict) # scale_pos_weight=class_weight_dict\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
